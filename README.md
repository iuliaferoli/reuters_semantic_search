# reuters_semantic_search

The main point of this blog is:

* there are many data science considerations to be made when working with NLP
* as much as current tools make it easier to use LLMs out of the box;
  * performance and relevance will always rely on how these are implemented.
* there are many techniques on how to optimize LLMs, both in literature and in terms of tools in the ecosystem.
  * Some may be better suited for a task than others,
  * and as always experts still need to interprpet the results
* hypothesis and testing are a core part of developing such models.
* there is something to be said about the value of experimenting.
  * Were the tasks we chose for this blog the best options?
  * Did they give us a clear winner from the models?
  * Maybe not. And that's what the answer may often be when doing these kind of tests. Doesn't make them any less valuable.
* Data science & research as a starting point / perspective vs out of the box solutions.
  * Find the right balance.




some references dump

https://huggingface.co/datasets/reuters21578

https://openreview.net/forum?id=wCu6T5xFjeJ
https://www.researchgate.net/publication/228362272_Evaluating_Semantic_Search_Tools_using_the_SEALS_platform
https://iopscience.iop.org/article/10.1088/1742-6596/1694/1/012004/pdf
https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=5ecc9f7043f6f2d7976b116a8d51ff81cd951b7f
https://openreview.net/pdf?id=wCu6T5xFjeJ 
https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)
https://python.langchain.com/docs/guides/evaluation/
https://api.python.langchain.com/en/stable/langchain_api_reference.html#module-langchain.evaluation
